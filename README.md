# neuralnetwork

## For August 3
- [ ] Find or recreate your work for performing a forward pass by hand.
- [ ] Add bias vectors to the neural network class; use them in the forward pass method.
- [ ] Finish adding print statements in the forward pass method which execute only when the 'verbose' parameter is 'true'.

## For July 28
- [ ] Check the computations of the forward pass method by hand. Do it once by thinking of it as a neural network; do it again by thinking of it as matrix operations.
- [ ] Stetch goal: for some other input, do it out again (both ways if you like) and then only run the code afterwards for that input to see if you get the same result as the code.
- [ ] If you have extra time, go ahead with biases and/or sigmoid activations. We'll work on this next session if all else is going well.



## For July 26
- [ ] Finish implementing the forward pass method using the matrix operation methods in the Matrix class. Text me if you have any trouble with this.
- [ ] Convince yourself that it works by using the Main (client) class to create a small network, performing the forward pass, and checking the computation by hand. Help yourself out by printing more than just the input and output (also print the hidden layer's activation as well as the weights of the network).
- [ ] Stretch goal: re-watch the video I sent you and notice that there is also usually a "bias" vector for each layer that gets added on to the result of multiplication with the weight matrices. See if you can add bias vectors to the NeuralNetwork class and correctly instantiate them in the constructor(s) as well as apply them correctly in the forward pass code. (If you are worried you may get stuck, go ahead and 'push' your working code to this github repo before continuing to work; then you can always restore your code to that functioning checkpoint.)


## At some point
- [ ] Forward pass
- [ ] Backpropogation
- [ ] Visualization
